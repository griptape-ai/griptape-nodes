# /// script
# dependencies = []
# 
# [tool.griptape-nodes]
# name = "Qwen-Image - Band Poster"
# schema_version = "0.14.0"
# engine_version_created_with = "0.66.0"
# node_libraries_referenced = [["Griptape Nodes Library", "0.52.6"]]
# node_types_used = [["Griptape Nodes Library", "Agent"], ["Griptape Nodes Library", "EndFlow"], ["Griptape Nodes Library", "MergeTexts"], ["Griptape Nodes Library", "Note"], ["Griptape Nodes Library", "QwenImageGeneration"], ["Griptape Nodes Library", "Ruleset"], ["Griptape Nodes Library", "StartFlow"]]
# is_griptape_provided = true
# creation_date = 2025-12-18T14:43:05.576659Z
# last_modified_date = "2025-12-18T15:06:02.234015Z"
# workflow_shape = "{\"inputs\":{\"Start Flow\":{\"exec_out\":{\"name\":\"exec_out\",\"tooltip\":\"Connection to the next node in the execution chain\",\"type\":\"parametercontroltype\",\"input_types\":[\"parametercontroltype\"],\"output_type\":\"parametercontroltype\",\"default_value\":null,\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"display_name\":\"Flow Out\"},\"settable\":true,\"is_user_defined\":true,\"parent_container_name\":null,\"parent_element_name\":null},\"text\":{\"name\":\"text\",\"tooltip\":\"New parameter\",\"type\":\"str\",\"input_types\":[\"any\"],\"output_type\":\"str\",\"default_value\":\"\",\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"multiline\":true,\"placeholder_text\":\"The text content to display\",\"hide_label\":false,\"hide_property\":false,\"is_custom\":true,\"is_user_added\":true,\"hide\":false,\"display_name\":\"subject\"},\"settable\":true,\"is_user_defined\":true,\"parent_container_name\":\"\",\"parent_element_name\":null},\"text_1\":{\"name\":\"text_1\",\"tooltip\":\"New parameter\",\"type\":\"str\",\"input_types\":[\"any\"],\"output_type\":\"str\",\"default_value\":\"\",\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"multiline\":true,\"placeholder_text\":\"The text content to display\",\"hide_label\":false,\"hide_property\":false,\"is_custom\":true,\"is_user_added\":true,\"hide\":false,\"display_name\":\"decade\"},\"settable\":true,\"is_user_defined\":true,\"parent_container_name\":\"\",\"parent_element_name\":null}}},\"outputs\":{\"End Flow\":{\"exec_in\":{\"name\":\"exec_in\",\"tooltip\":\"Control path when the flow completed successfully\",\"type\":\"parametercontroltype\",\"input_types\":[\"parametercontroltype\"],\"output_type\":\"parametercontroltype\",\"default_value\":null,\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"display_name\":\"Succeeded\"},\"settable\":true,\"is_user_defined\":true,\"parent_container_name\":null,\"parent_element_name\":null},\"failed\":{\"name\":\"failed\",\"tooltip\":\"Control path when the flow failed\",\"type\":\"parametercontroltype\",\"input_types\":[\"parametercontroltype\"],\"output_type\":\"parametercontroltype\",\"default_value\":null,\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"display_name\":\"Failed\"},\"settable\":true,\"is_user_defined\":true,\"parent_container_name\":null,\"parent_element_name\":null},\"was_successful\":{\"name\":\"was_successful\",\"tooltip\":\"Indicates whether it completed without errors.\",\"type\":\"bool\",\"input_types\":[\"bool\"],\"output_type\":\"bool\",\"default_value\":false,\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{},\"settable\":false,\"is_user_defined\":true,\"parent_container_name\":null,\"parent_element_name\":null},\"result_details\":{\"name\":\"result_details\",\"tooltip\":\"Details about the operation result\",\"type\":\"str\",\"input_types\":[\"str\"],\"output_type\":\"str\",\"default_value\":null,\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"multiline\":true,\"placeholder_text\":\"Details about the completion or failure will be shown here.\"},\"settable\":false,\"is_user_defined\":true,\"parent_container_name\":null,\"parent_element_name\":null},\"image_url\":{\"name\":\"image_url\",\"tooltip\":\"New parameter\",\"type\":\"ImageUrlArtifact\",\"input_types\":[\"ImageUrlArtifact\"],\"output_type\":\"ImageUrlArtifact\",\"default_value\":\"\",\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"is_full_width\":true,\"pulse_on_run\":true,\"is_custom\":true,\"is_user_added\":true},\"settable\":true,\"is_user_defined\":true,\"parent_container_name\":\"\",\"parent_element_name\":null}}}}"
# description = "Create a decade-specific band poster using Qwen-Image to generate an image and OpenAI gpt-4.1-mini to help design the prompt."
# is_template = true
# image = "https://raw.githubusercontent.com/griptape-ai/griptape-nodes/refs/heads/main/libraries/griptape_nodes_library/workflows/templates/thumbnail_qwen-image_-_band_poster.webp"
# 
# ///

import argparse
import asyncio
import json
import pickle
from griptape.artifacts.image_url_artifact import ImageUrlArtifact
from griptape.rules.ruleset import Ruleset
from griptape_nodes.bootstrap.workflow_executors.local_workflow_executor import LocalWorkflowExecutor
from griptape_nodes.bootstrap.workflow_executors.workflow_executor import WorkflowExecutor
from griptape_nodes.drivers.storage.storage_backend import StorageBackend
from griptape_nodes.node_library.library_registry import IconVariant, NodeDeprecationMetadata, NodeMetadata
from griptape_nodes.retained_mode.events.connection_events import CreateConnectionRequest
from griptape_nodes.retained_mode.events.flow_events import CreateFlowRequest, GetTopLevelFlowRequest, GetTopLevelFlowResultSuccess
from griptape_nodes.retained_mode.events.library_events import LoadLibrariesRequest
from griptape_nodes.retained_mode.events.node_events import CreateNodeRequest
from griptape_nodes.retained_mode.events.parameter_events import AddParameterToNodeRequest, AlterParameterDetailsRequest, SetParameterValueRequest
from griptape_nodes.retained_mode.griptape_nodes import GriptapeNodes

GriptapeNodes.handle_request(LoadLibrariesRequest())

context_manager = GriptapeNodes.ContextManager()

if not context_manager.has_current_workflow():
    context_manager.push_workflow(workflow_name='Qwen-Image - Band Poster')

"""
1. We've collated all of the unique parameter values into a dictionary so that we do not have to duplicate them.
   This minimizes the size of the code, especially for large objects like serialized image files.
2. We're using a prefix so that it's clear which Flow these values are associated with.
3. The values are serialized using pickle, which is a binary format. This makes them harder to read, but makes
   them consistently save and load. It allows us to serialize complex objects like custom classes, which otherwise
   would be difficult to serialize.
"""
top_level_unique_values_dict = {'1182052f-86f6-4481-a226-b48d679585ad': pickle.loads(b'\x80\x04\x95\x11\x00\x00\x00\x00\x00\x00\x00\x8c\rThe Capybaras\x94.'), '11e2fdf7-4cf1-4512-b8ec-e7ef9ab5d641': pickle.loads(b'\x80\x04\x95\t\x00\x00\x00\x00\x00\x00\x00\x8c\x051960s\x94.'), '2bb96655-39e1-40b5-805b-62540ca544ea': pickle.loads(b'\x80\x04\x95G\x15\x00\x00\x00\x00\x00\x00}\x94(\x8c\x04type\x94\x8c\x12GriptapeNodesAgent\x94\x8c\x08rulesets\x94]\x94}\x94(h\x01\x8c\x07Ruleset\x94\x8c\x02id\x94\x8c 90289c39945741e7856e0f91ccb6b716\x94\x8c\x04name\x94\x8c\x15Qwen  Prompting Guide\x94\x8c\x04meta\x94}\x94\x8c\x05rules\x94]\x94(}\x94(h\x01\x8c\x04Rule\x94\x8c\x05value\x94\x8c\x1f**Rules for Crafting Prompts:**\x94u}\x94(h\x01h\x10h\x11\x8c\xc9Use the following prompt formula when generating prompts:\nPrompt = Subject (Subject Description) + Scene (Scene Description) + Style (Define Style) + Lens Language + Atmosphere Words + Detail Modifiers\x94u}\x94(h\x01h\x10h\x11\x8c\xb4**Subject Description:**\nClearly describe the subject in the image, including its characteristics, actions, etc. For example, "a cute 10-year-old Chinese girl wearing red clothes".\x94u}\x94(h\x01h\x10h\x11\x8c\xb2**Scene Description:**\nScene description is a detailed description of the environmental characteristics of the subject, which can be listed through adjectives or short sentences.\x94u}\x94(h\x01h\x10h\x11\x8c\xcf**Define Style:**\nDefine style is to clearly describe the specific artistic style, expression technique, or visual characteristics that the image should have. For example, "watercolor style", "comic style". \x94u}\x94(h\x01h\x10h\x11\x8cGCommon stylization details can be found in the prompt dictionary below.\x94u}\x94(h\x01h\x10h\x11\x8c\x12**Lens Language:**\x94u}\x94(h\x01h\x10h\x11\x8cmLens language includes framing, perspective, etc. Common lens language can be found in the prompt dictionary.\x94u}\x94(h\x01h\x10h\x11\x8c\xc5**Atmosphere Words:**\nAtmosphere words are descriptions of the expected picture atmosphere, such as "dreamy", "lonely", "magnificent". Common atmosphere words can be found in the prompt dictionary.\x94u}\x94(h\x01h\x10h\x11X\t\x01\x00\x00**Detail Modifiers:**\nDetail modifiers are further refinement and optimization of the picture to enhance the image\'s detail expressiveness, richness, and beauty. For example, "light source position", "prop matching", "environmental details", "high resolution", etc.\x94u}\x94(h\x01h\x10h\x11\x8c\xaf**Advanced Techniques**\n1. Style Mixing\n"Portrait of a cyberpunk samurai, blend of traditional Japanese art \nand neon futurism, style of Katsushika Hokusai meets Blade Runner"\x94u}\x94(h\x01h\x10h\x11\x8c\x8e2. Weighted Elements\n"Beautiful landscape with (mountains:1.5), (lake:1.2), (forest:0.8),\ngolden hour lighting, ultra detailed, 8k resolution"\x94u}\x94(h\x01h\x10h\x11\x8c|3. Negative Prompts\nPrompt: "Elegant minimalist logo design"\nNegative: "complex, busy, cluttered, photorealistic, 3D render"\x94u}\x94(h\x01h\x10h\x11X\x87\x01\x00\x00# Prompt Dictionary\n## Framing: \nFraming refers to the difference in the range size of the subject presented in the image due to the different distances between the camera and the subject being photographed. It can generally be divided into long shot, full shot, medium shot, close-up, extreme close-up, etc. Here are some framing examples:\nExtreme Close-up, Close-up, Medium Shot, Long Shot\x94u}\x94(h\x01h\x10h\x11\x8c\xb4## Perspective:\nLens perspective, that is, the perspective chosen when the camera shoots the picture. Here are some perspective examples:\nEye Level, High Angle, Low Angle, Aerial, \x94u}\x94(h\x01h\x10h\x11\x8c\xe9## Lens Type:\nLens type refers to the different types of camera lenses divided according to different focal lengths, functions, application scenarios, etc. Here are some lens type examples:\nMacro, Ultra Wide Angle, Telephoto, Fisheye\x94u}\x94(h\x01h\x10h\x11\x8c\xf7## Style\nDefine style is to clearly describe the specific artistic style, expression technique, or visual characteristics that the image should have. Here are some style type examples:\n3D Cartoon, Post-apocalyptic, pointillism, surreal, watercolor\x94u}\x94(h\x01h\x10h\x11\x8c\xcf## Lighting\nDifferent types of lighting can create various atmospheres and effects, meeting different creative needs. Here are some lighting type examples:\nNatural light, backlight, neon light, ambient light\x94u}\x94(h\x01h\x10h\x11\x8c9Important: Add specific details to make the prompt unique\x94ueuah\r]\x94h\x07\x8c dd0c626a18fd4e09b1b05f43c00b7f40\x94\x8c\x13conversation_memory\x94}\x94(h\x01\x8c\x12ConversationMemory\x94\x8c\x04runs\x94]\x94}\x94(h\x01\x8c\x03Run\x94h\x07\x8c 3763d31a3f9e44e6b9aef86895f0d3fa\x94h\x0bN\x8c\x05input\x94}\x94(h\x01\x8c\x0cTextArtifact\x94h\x07\x8c 33386e7388a74f498c0482a9d6ac08f7\x94\x8c\treference\x94Nh\x0b}\x94h\thDh\x11X\x00\x01\x00\x00Create a band poster from specified decade of the following band. Include dates and some creative support bands. \n\nMake the image and article titles authentic to the time period.\n\nOutput only the Image Generation Prompt\nSubject:\nThe Capybaras\nDecade:\n1960s\x94u\x8c\x06output\x94}\x94(h\x01hCh\x07\x8c 2fb0d0a3cfa94b6db969eed63a46f519\x94hENh\x0b}\x94\x8c\x0fis_react_prompt\x94\x89sh\thJh\x11X\x11\x03\x00\x00The Capybaras (a lively 1960s British rock band with mod fashion and energetic stage presence) + Scene (a vibrant 1960s concert poster featuring psychedelic patterns, bold colorful swirls, and vintage typography, with The Capybaras front and center playing guitars and drums, surrounded by creative support bands "The Electric Peacocks" and "The Velvet Tides", dates listed as "Summer Tour 1967: July 10 - August 25") + Style (psychedelic 1960s poster art style with hand-drawn illustrations and groovy fonts) + Lens Language (medium shot framing of band members integrated into poster design) + Atmosphere Words (energetic, vibrant, retro, psychedelic, lively) + Detail Modifiers (bold contrasting colors, vintage paper texture, intricate floral and paisley patterns, high resolution)\x94uuah\x0b}\x94\x8c\x08max_runs\x94Nu\x8c\x1cconversation_memory_strategy\x94\x8c\rper_structure\x94\x8c\x05tasks\x94]\x94}\x94(h\x01\x8c\nPromptTask\x94h\x03]\x94h\r]\x94h\x07\x8c 905913cdc8864803a603eff9ea09034b\x94\x8c\x05state\x94\x8c\x0eState.FINISHED\x94\x8c\nparent_ids\x94]\x94\x8c\tchild_ids\x94]\x94\x8c\x17max_meta_memory_entries\x94K\x14\x8c\x07context\x94}\x94\x8c\rprompt_driver\x94}\x94(h\x01\x8c\x19GriptapeCloudPromptDriver\x94\x8c\x0btemperature\x94G?\xb9\x99\x99\x99\x99\x99\x9a\x8c\nmax_tokens\x94N\x8c\x06stream\x94\x88\x8c\x0cextra_params\x94}\x94\x8c\x05model\x94\x8c\x0cgpt-4.1-mini\x94\x8c\x1astructured_output_strategy\x94\x8c\x06native\x94u\x8c\x05tools\x94]\x94\x8c\x0cmax_subtasks\x94K\x14uau.'), '42107c41-547c-4268-a93e-e69bed45b74d': pickle.loads(b'\x80\x04\x95\x10\x00\x00\x00\x00\x00\x00\x00\x8c\x0cgpt-4.1-mini\x94.'), 'd2df5eb3-bf4f-493d-b988-937bf54832f6': pickle.loads(b'\x80\x04\x95\xdf\x00\x00\x00\x00\x00\x00\x00\x8c\xdbCreate a band poster from specified decade of the following band. Include dates and some creative support bands. \n\nMake the image and article titles authentic to the time period.\n\nOutput only the Image Generation Prompt\x94.'), 'ca72951e-71df-4c87-96a2-fb8aa12529db': pickle.loads(b'\x80\x04\x95(\x00\x00\x00\x00\x00\x00\x00\x8c$Subject:\nThe Capybaras\nDecade:\n1960s\x94.'), '376e3e18-6eaa-4328-bf4b-1a35dfe4c966': pickle.loads(b'\x80\x04]\x94.'), '996f725e-95a8-4964-b6da-959fcbf05584': pickle.loads(b'\x80\x04\x95`\x10\x00\x00\x00\x00\x00\x00]\x94\x8c\x16griptape.rules.ruleset\x94\x8c\x07Ruleset\x94\x93\x94)\x81\x94}\x94(\x8c\x04type\x94\x8c\x07Ruleset\x94\x8c\x0bmodule_name\x94\x8c\x16griptape.rules.ruleset\x94\x8c\x02id\x94\x8c 90289c39945741e7856e0f91ccb6b716\x94\x8c\x04name\x94\x8c\x15Qwen  Prompting Guide\x94\x8c\x0eruleset_driver\x94\x8c-griptape.drivers.ruleset.local_ruleset_driver\x94\x8c\x12LocalRulesetDriver\x94\x93\x94)\x81\x94}\x94(h\x06\x8c\x12LocalRulesetDriver\x94h\x08\x8c-griptape.drivers.ruleset.local_ruleset_driver\x94\x8c\x0fraise_not_found\x94\x88\x8c\x0bpersist_dir\x94Nub\x8c\x04meta\x94}\x94\x8c\x05rules\x94]\x94(\x8c\x13griptape.rules.rule\x94\x8c\x04Rule\x94\x93\x94)\x81\x94}\x94(h\x06\x8c\x04Rule\x94h\x08\x8c\x13griptape.rules.rule\x94h\x18}\x94\x8c\x05value\x94\x8c\x1f**Rules for Crafting Prompts:**\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xc9Use the following prompt formula when generating prompts:\nPrompt = Subject (Subject Description) + Scene (Scene Description) + Style (Define Style) + Lens Language + Atmosphere Words + Detail Modifiers\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xb4**Subject Description:**\nClearly describe the subject in the image, including its characteristics, actions, etc. For example, "a cute 10-year-old Chinese girl wearing red clothes".\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xb2**Scene Description:**\nScene description is a detailed description of the environmental characteristics of the subject, which can be listed through adjectives or short sentences.\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xcf**Define Style:**\nDefine style is to clearly describe the specific artistic style, expression technique, or visual characteristics that the image should have. For example, "watercolor style", "comic style". \x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8cGCommon stylization details can be found in the prompt dictionary below.\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\x12**Lens Language:**\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8cmLens language includes framing, perspective, etc. Common lens language can be found in the prompt dictionary.\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xc5**Atmosphere Words:**\nAtmosphere words are descriptions of the expected picture atmosphere, such as "dreamy", "lonely", "magnificent". Common atmosphere words can be found in the prompt dictionary.\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$X\t\x01\x00\x00**Detail Modifiers:**\nDetail modifiers are further refinement and optimization of the picture to enhance the image\'s detail expressiveness, richness, and beauty. For example, "light source position", "prop matching", "environmental details", "high resolution", etc.\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xaf**Advanced Techniques**\n1. Style Mixing\n"Portrait of a cyberpunk samurai, blend of traditional Japanese art \nand neon futurism, style of Katsushika Hokusai meets Blade Runner"\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\x8e2. Weighted Elements\n"Beautiful landscape with (mountains:1.5), (lake:1.2), (forest:0.8),\ngolden hour lighting, ultra detailed, 8k resolution"\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c|3. Negative Prompts\nPrompt: "Elegant minimalist logo design"\nNegative: "complex, busy, cluttered, photorealistic, 3D render"\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$X\x87\x01\x00\x00# Prompt Dictionary\n## Framing: \nFraming refers to the difference in the range size of the subject presented in the image due to the different distances between the camera and the subject being photographed. It can generally be divided into long shot, full shot, medium shot, close-up, extreme close-up, etc. Here are some framing examples:\nExtreme Close-up, Close-up, Medium Shot, Long Shot\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xb4## Perspective:\nLens perspective, that is, the perspective chosen when the camera shoots the picture. Here are some perspective examples:\nEye Level, High Angle, Low Angle, Aerial, \x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xe9## Lens Type:\nLens type refers to the different types of camera lenses divided according to different focal lengths, functions, application scenarios, etc. Here are some lens type examples:\nMacro, Ultra Wide Angle, Telephoto, Fisheye\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xf7## Style\nDefine style is to clearly describe the specific artistic style, expression technique, or visual characteristics that the image should have. Here are some style type examples:\n3D Cartoon, Post-apocalyptic, pointillism, surreal, watercolor\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xcf## Lighting\nDifferent types of lighting can create various atmospheres and effects, meeting different creative needs. Here are some lighting type examples:\nNatural light, backlight, neon light, ambient light\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c9Important: Add specific details to make the prompt unique\x94ubeuba.'), '2ea5037d-1b26-4d06-ba6f-a3b602f5cfe4': pickle.loads(b'\x80\x04\x95]\x10\x00\x00\x00\x00\x00\x00\x8c\x16griptape.rules.ruleset\x94\x8c\x07Ruleset\x94\x93\x94)\x81\x94}\x94(\x8c\x04type\x94\x8c\x07Ruleset\x94\x8c\x0bmodule_name\x94\x8c\x16griptape.rules.ruleset\x94\x8c\x02id\x94\x8c 90289c39945741e7856e0f91ccb6b716\x94\x8c\x04name\x94\x8c\x15Qwen  Prompting Guide\x94\x8c\x0eruleset_driver\x94\x8c-griptape.drivers.ruleset.local_ruleset_driver\x94\x8c\x12LocalRulesetDriver\x94\x93\x94)\x81\x94}\x94(h\x05\x8c\x12LocalRulesetDriver\x94h\x07\x8c-griptape.drivers.ruleset.local_ruleset_driver\x94\x8c\x0fraise_not_found\x94\x88\x8c\x0bpersist_dir\x94Nub\x8c\x04meta\x94}\x94\x8c\x05rules\x94]\x94(\x8c\x13griptape.rules.rule\x94\x8c\x04Rule\x94\x93\x94)\x81\x94}\x94(h\x05\x8c\x04Rule\x94h\x07\x8c\x13griptape.rules.rule\x94h\x17}\x94\x8c\x05value\x94\x8c\x1f**Rules for Crafting Prompts:**\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xc9Use the following prompt formula when generating prompts:\nPrompt = Subject (Subject Description) + Scene (Scene Description) + Style (Define Style) + Lens Language + Atmosphere Words + Detail Modifiers\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xb4**Subject Description:**\nClearly describe the subject in the image, including its characteristics, actions, etc. For example, "a cute 10-year-old Chinese girl wearing red clothes".\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xb2**Scene Description:**\nScene description is a detailed description of the environmental characteristics of the subject, which can be listed through adjectives or short sentences.\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xcf**Define Style:**\nDefine style is to clearly describe the specific artistic style, expression technique, or visual characteristics that the image should have. For example, "watercolor style", "comic style". \x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8cGCommon stylization details can be found in the prompt dictionary below.\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\x12**Lens Language:**\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8cmLens language includes framing, perspective, etc. Common lens language can be found in the prompt dictionary.\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xc5**Atmosphere Words:**\nAtmosphere words are descriptions of the expected picture atmosphere, such as "dreamy", "lonely", "magnificent". Common atmosphere words can be found in the prompt dictionary.\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#X\t\x01\x00\x00**Detail Modifiers:**\nDetail modifiers are further refinement and optimization of the picture to enhance the image\'s detail expressiveness, richness, and beauty. For example, "light source position", "prop matching", "environmental details", "high resolution", etc.\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xaf**Advanced Techniques**\n1. Style Mixing\n"Portrait of a cyberpunk samurai, blend of traditional Japanese art \nand neon futurism, style of Katsushika Hokusai meets Blade Runner"\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\x8e2. Weighted Elements\n"Beautiful landscape with (mountains:1.5), (lake:1.2), (forest:0.8),\ngolden hour lighting, ultra detailed, 8k resolution"\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c|3. Negative Prompts\nPrompt: "Elegant minimalist logo design"\nNegative: "complex, busy, cluttered, photorealistic, 3D render"\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#X\x87\x01\x00\x00# Prompt Dictionary\n## Framing: \nFraming refers to the difference in the range size of the subject presented in the image due to the different distances between the camera and the subject being photographed. It can generally be divided into long shot, full shot, medium shot, close-up, extreme close-up, etc. Here are some framing examples:\nExtreme Close-up, Close-up, Medium Shot, Long Shot\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xb4## Perspective:\nLens perspective, that is, the perspective chosen when the camera shoots the picture. Here are some perspective examples:\nEye Level, High Angle, Low Angle, Aerial, \x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xe9## Lens Type:\nLens type refers to the different types of camera lenses divided according to different focal lengths, functions, application scenarios, etc. Here are some lens type examples:\nMacro, Ultra Wide Angle, Telephoto, Fisheye\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xf7## Style\nDefine style is to clearly describe the specific artistic style, expression technique, or visual characteristics that the image should have. Here are some style type examples:\n3D Cartoon, Post-apocalyptic, pointillism, surreal, watercolor\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xcf## Lighting\nDifferent types of lighting can create various atmospheres and effects, meeting different creative needs. Here are some lighting type examples:\nNatural light, backlight, neon light, ambient light\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c9Important: Add specific details to make the prompt unique\x94ubeub.'), '6b22c22d-0597-43d6-9533-d4916b22e5d6': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00\x8c\x00\x94.'), 'a01ddd3e-ced9-4d56-8d6d-c41c881e47d2': pickle.loads(b'\x80\x04\x95\x18\x03\x00\x00\x00\x00\x00\x00X\x11\x03\x00\x00The Capybaras (a lively 1960s British rock band with mod fashion and energetic stage presence) + Scene (a vibrant 1960s concert poster featuring psychedelic patterns, bold colorful swirls, and vintage typography, with The Capybaras front and center playing guitars and drums, surrounded by creative support bands "The Electric Peacocks" and "The Velvet Tides", dates listed as "Summer Tour 1967: July 10 - August 25") + Style (psychedelic 1960s poster art style with hand-drawn illustrations and groovy fonts) + Lens Language (medium shot framing of band members integrated into poster design) + Atmosphere Words (energetic, vibrant, retro, psychedelic, lively) + Detail Modifiers (bold contrasting colors, vintage paper texture, intricate floral and paisley patterns, high resolution)\x94.'), 'e84f5751-0f21-4276-9c40-9b043a1e3c74': pickle.loads(b'\x80\x04\x89.'), 'b84f346a-f57f-4eb4-8457-71f3efa23eca': pickle.loads(b'\x80\x04\x95N\x00\x00\x00\x00\x00\x00\x00\x8cJ[Processing..]\n[Started processing agent..]\n\n[Finished processing agent.]\n\x94.'), '09b7071b-fcab-400c-968d-69b9663e8c32': pickle.loads(b'\x80\x04\x95\x18\x00\x00\x00\x00\x00\x00\x00\x8c\x14Qwen Prompting Guide\x94.'), 'e7f7f653-9acf-4141-9c1b-89f8c2d4e55b': pickle.loads(b'\x80\x04\x95\xb8\x0c\x00\x00\x00\x00\x00\x00X\xb1\x0c\x00\x00**Rules for Crafting Prompts:**\n\nUse the following prompt formula when generating prompts:\nPrompt = Subject (Subject Description) + Scene (Scene Description) + Style (Define Style) + Lens Language + Atmosphere Words + Detail Modifiers\n\n**Subject Description:**\nClearly describe the subject in the image, including its characteristics, actions, etc. For example, "a cute 10-year-old Chinese girl wearing red clothes".\n\n**Scene Description:**\nScene description is a detailed description of the environmental characteristics of the subject, which can be listed through adjectives or short sentences.\n\n**Define Style:**\nDefine style is to clearly describe the specific artistic style, expression technique, or visual characteristics that the image should have. For example, "watercolor style", "comic style". \n\nCommon stylization details can be found in the prompt dictionary below.\n\n**Lens Language:**\n\nLens language includes framing, perspective, etc. Common lens language can be found in the prompt dictionary.\n\n**Atmosphere Words:**\nAtmosphere words are descriptions of the expected picture atmosphere, such as "dreamy", "lonely", "magnificent". Common atmosphere words can be found in the prompt dictionary.\n\n**Detail Modifiers:**\nDetail modifiers are further refinement and optimization of the picture to enhance the image\'s detail expressiveness, richness, and beauty. For example, "light source position", "prop matching", "environmental details", "high resolution", etc.\n\n**Advanced Techniques**\n1. Style Mixing\n"Portrait of a cyberpunk samurai, blend of traditional Japanese art \nand neon futurism, style of Katsushika Hokusai meets Blade Runner"\n\n2. Weighted Elements\n"Beautiful landscape with (mountains:1.5), (lake:1.2), (forest:0.8),\ngolden hour lighting, ultra detailed, 8k resolution"\n\n3. Negative Prompts\nPrompt: "Elegant minimalist logo design"\nNegative: "complex, busy, cluttered, photorealistic, 3D render"\n\n# Prompt Dictionary\n## Framing: \nFraming refers to the difference in the range size of the subject presented in the image due to the different distances between the camera and the subject being photographed. It can generally be divided into long shot, full shot, medium shot, close-up, extreme close-up, etc. Here are some framing examples:\nExtreme Close-up, Close-up, Medium Shot, Long Shot\n\n## Perspective:\nLens perspective, that is, the perspective chosen when the camera shoots the picture. Here are some perspective examples:\nEye Level, High Angle, Low Angle, Aerial, \n\n## Lens Type:\nLens type refers to the different types of camera lenses divided according to different focal lengths, functions, application scenarios, etc. Here are some lens type examples:\nMacro, Ultra Wide Angle, Telephoto, Fisheye\n\n## Style\nDefine style is to clearly describe the specific artistic style, expression technique, or visual characteristics that the image should have. Here are some style type examples:\n3D Cartoon, Post-apocalyptic, pointillism, surreal, watercolor\n\n## Lighting\nDifferent types of lighting can create various atmospheres and effects, meeting different creative needs. Here are some lighting type examples:\nNatural light, backlight, neon light, ambient light\n\nImportant: Add specific details to make the prompt unique\x94.'), 'e8c05586-a913-472e-8658-eb312bd90ab4': pickle.loads(b'\x80\x04\x95\x0c\x00\x00\x00\x00\x00\x00\x00\x8c\x08Subject:\x94.'), 'abf0c0a0-d879-4df7-ae43-7d110bc6abc6': pickle.loads(b'\x80\x04\x95\x0b\x00\x00\x00\x00\x00\x00\x00\x8c\x07Decade:\x94.'), 'ebd6d0ac-f804-4c57-b860-ee8c13c47f95': pickle.loads(b'\x80\x04\x95\x06\x00\x00\x00\x00\x00\x00\x00\x8c\x02\\n\x94.'), '81ea17a7-2292-4d6b-abbd-2fe2d78746b9': pickle.loads(b'\x80\x04\x88.'), '3f73ef8c-0593-4d6e-acb3-2976bafa2d1b': pickle.loads(b'\x80\x04\x95R\x00\x00\x00\x00\x00\x00\x00\x8cN[SUCCEEDED] No connection provided for success or failure, assuming successful\x94.'), '38e19e07-2a34-442c-857f-161492bbb3d9': pickle.loads(b'\x80\x04\x95\x8a\x01\x00\x00\x00\x00\x00\x00\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x10ImageUrlArtifact\x94\x93\x94)\x81\x94}\x94(\x8c\x04type\x94\x8c\x10ImageUrlArtifact\x94\x8c\x0bmodule_name\x94\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x02id\x94\x8c d4c9bcfb3f0d417090dda89a5026d5b3\x94\x8c\treference\x94N\x8c\x04meta\x94}\x94\x8c\x04name\x94\x8c\x19qwen_image_1766020942.jpg\x94\x8c\x16encoding_error_handler\x94\x8c\x06strict\x94\x8c\x08encoding\x94\x8c\x05utf-8\x94\x8c\x05value\x94\x8cShttp://localhost:8124/workspace/static_files/qwen_image_1766020942.jpg?t=1766020942\x94ub.'), 'efb54591-47a3-4245-8f6e-1fe273bacf25': pickle.loads(b'\x80\x04\x95I\x00\x00\x00\x00\x00\x00\x00\x8cE# Inputs\n\nProvide a *subject* and a *decade* to create a band poster.\x94.'), '3f8fa8de-2bbb-4a07-8277-2a4a390d90bd': pickle.loads(b'\x80\x04\x95D\x00\x00\x00\x00\x00\x00\x00\x8c@This node merges text into a single message to send to an agent.\x94.'), '1670e178-4d51-42e3-b7cb-d39e68d4746a': pickle.loads(b'\x80\x04\x95\xb0\x00\x00\x00\x00\x00\x00\x00\x8c\xac# Agent Behavior\n\nThese rules are adapted from the [Qwen Prompting Guide](https://www.qwenimagen.com/prompt-guide) and are given to the agent to help guide their responses.\x94.'), 'bbd5afde-e94b-4bf9-a398-ca5095fb5752': pickle.loads(b'\x80\x04\x95\x95\x00\x00\x00\x00\x00\x00\x00\x8c\x91Using Agents to create image generation prompts helps ensure consistency in the prompt, and allows you to be a bit more free with how you prompt.\x94.'), 'c6b912d9-1c40-4af6-8b14-8868710d114e': pickle.loads(b'\x80\x04\x95!\x00\x00\x00\x00\x00\x00\x00\x8c\x1dGenerate the Image using Qwen\x94.'), '826ef3b9-af7f-46b2-8aeb-bf8742d59203': pickle.loads(b'\x80\x04\x959\x00\x00\x00\x00\x00\x00\x00\x8c5# End Flow\n\nThe flow will return the resulting image.\x94.'), 'bef04d2b-be18-451e-8de3-a7a460d8654e': pickle.loads(b'\x80\x04\x95\x0e\x00\x00\x00\x00\x00\x00\x00\x8c\nqwen-image\x94.'), '065f2b01-0d2b-4d6f-bd10-9443a7bd768b': pickle.loads(b'\x80\x04\x95\r\x00\x00\x00\x00\x00\x00\x00\x8c\t1328*1328\x94.'), '32a1389a-3951-4515-8111-c179bff467f1': pickle.loads(b'\x80\x04K*.')}

'# Create the Flow, then do work within it as context.'

flow0_name = GriptapeNodes.handle_request(CreateFlowRequest(parent_flow_name=None, flow_name='ControlFlow_1', set_as_new_context=False, metadata={})).flow_name

with GriptapeNodes.ContextManager().flow(flow0_name):
    node0_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='StartFlow', specific_library_name='Griptape Nodes Library', node_name='Start Flow', metadata={'position': {'x': -303.0843370080777, 'y': 296.93529465485886}, 'tempId': 'placing-1765996350930-qa8fpl', 'library_node_metadata': {'category': 'workflows', 'description': 'Define the start of a workflow and pass parameters into the flow'}, 'library': 'Griptape Nodes Library', 'node_type': 'StartFlow', 'showaddparameter': True, 'size': {'width': 600, 'height': 347}, 'category': 'workflows'}, resolution='resolved', initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node0_name):
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='text', default_value='', tooltip='New parameter', type='str', input_types=['any'], output_type='str', ui_options={'multiline': True, 'placeholder_text': 'The text content to display', 'hide_label': False, 'hide_property': False, 'is_custom': True, 'is_user_added': True, 'hide': False, 'display_name': 'subject'}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, parent_container_name='', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='text_1', default_value='', tooltip='New parameter', type='str', input_types=['any'], output_type='str', ui_options={'multiline': True, 'placeholder_text': 'The text content to display', 'hide_label': False, 'hide_property': False, 'is_custom': True, 'is_user_added': True, 'hide': False, 'display_name': 'decade'}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, parent_container_name='', initial_setup=True))
    node1_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Agent', specific_library_name='Griptape Nodes Library', node_name='Agent_1', metadata={'position': {'x': 1405.5567786383533, 'y': 296.93529465485886}, 'tempId': 'placing-1765998525786-f45x3l', 'library_node_metadata': {'category': 'agents', 'description': 'Creates an AI agent with conversation memory and the ability to use tools'}, 'library': 'Griptape Nodes Library', 'node_type': 'Agent', 'showaddparameter': False, 'size': {'width': 600, 'height': 1179}, 'category': 'agents'}, initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node1_name):
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='additional_context', mode_allowed_property=False, initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='tools', ui_options={'hide': True}, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='rulesets_ParameterListUniqueParamID_6df8ae9c0e1a4a1881fc4f3986fbab35', default_value=[], tooltip='Rulesets to apply to the agent to control its behavior.', type='Ruleset', input_types=['Ruleset', 'list[Ruleset]'], output_type='Ruleset', ui_options={}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='rulesets', initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='output_schema', ui_options={'hide_property': True, 'hide': True}, initial_setup=True))
    node2_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Ruleset', specific_library_name='Griptape Nodes Library', node_name='Ruleset_1', metadata={'position': {'x': 487.6351386036997, 'y': 1104.4096152628408}, 'tempId': 'placing-1765998085117-ktqra', 'library_node_metadata': {'category': 'agents/rules', 'description': 'Give an agent a set of rules and behaviors to follow'}, 'library': 'Griptape Nodes Library', 'node_type': 'Ruleset', 'showaddparameter': False, 'size': {'width': 723, 'height': 933}, 'category': 'agents/rules'}, initial_setup=True)).node_name
    node3_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='MergeTexts', specific_library_name='Griptape Nodes Library', node_name='Merge Texts', metadata={'position': {'x': 487.6351386036997, 'y': 296.93529465485886}, 'tempId': 'placing-1766002459782-pzdym9', 'library_node_metadata': {'category': 'text', 'description': 'MergeTexts node'}, 'library': 'Griptape Nodes Library', 'node_type': 'MergeTexts', 'showaddparameter': False, 'size': {'width': 600, 'height': 500}, 'category': 'text', 'empty_merge_string_migrated': True}, resolution='resolved', initial_setup=True)).node_name
    node4_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='EndFlow', specific_library_name='Griptape Nodes Library', node_name='End Flow', metadata={'position': {'x': 3230.0044593220005, 'y': 296.93529465485886}, 'tempId': 'placing-1766003522860-5ouiyv', 'library_node_metadata': {'category': 'workflows', 'description': 'Define the end of a workflow and return parameters from the flow'}, 'library': 'Griptape Nodes Library', 'node_type': 'EndFlow', 'showaddparameter': True, 'size': {'width': 945, 'height': 1244}, 'category': 'workflows'}, initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node4_name):
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='image_url', default_value='', tooltip='New parameter', type='ImageUrlArtifact', input_types=['ImageUrlArtifact'], output_type='ImageUrlArtifact', ui_options={'is_full_width': True, 'pulse_on_run': True, 'is_custom': True, 'is_user_added': True}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, parent_container_name='', initial_setup=True))
    node5_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 1', metadata={'position': {'x': -303.0843370080777, 'y': 66.8118912484619}, 'tempId': 'placing-1766003334530-pnkgh', 'library_node_metadata': {'category': 'misc', 'description': 'Create a note node to provide helpful context in your workflow'}, 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 605, 'height': 175}, 'category': 'misc'}, resolution='resolved', initial_setup=True)).node_name
    node6_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 2', metadata={'position': {'x': 487.6351386036997, 'y': 66.8118912484619}, 'tempId': 'placing-1766003370124-fo9hq', 'library_node_metadata': {'category': 'misc', 'description': 'Create a note node to provide helpful context in your workflow'}, 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 600, 'height': 170}, 'category': 'misc'}, resolution='resolved', initial_setup=True)).node_name
    node7_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 3', metadata={'position': {'x': 487.6351386036997, 'y': 890.6365870210909}, 'tempId': 'placing-1766003265679-b4mek', 'library_node_metadata': {'category': 'misc', 'description': 'Create a note node to provide helpful context in your workflow'}, 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 710, 'height': 192}, 'category': 'misc'}, resolution='resolved', initial_setup=True)).node_name
    node8_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 4', metadata={'position': {'x': 1405.5567786383533, 'y': 66.8118912484619}, 'tempId': 'placing-1766003370124-fo9hq', 'library_node_metadata': {'category': 'misc', 'description': 'Create a note node to provide helpful context in your workflow'}, 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 600, 'height': 163}, 'category': 'misc'}, resolution='resolved', initial_setup=True)).node_name
    node9_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 5', metadata={'position': {'x': 2216.14914549015, 'y': 66.8118912484619}, 'tempId': 'placing-1766003370124-fo9hq', 'library_node_metadata': {'category': 'misc', 'description': 'Create a note node to provide helpful context in your workflow'}, 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 722, 'height': 153}, 'category': 'misc'}, resolution='resolved', initial_setup=True)).node_name
    node10_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 6', metadata={'position': {'x': 3230.0044593220005, 'y': 71.8118912484619}, 'tempId': 'placing-1766003370124-fo9hq', 'library_node_metadata': {'category': 'misc', 'description': 'Create a note node to provide helpful context in your workflow'}, 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 722, 'height': 153}, 'category': 'misc'}, initial_setup=True)).node_name
    node11_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='QwenImageGeneration', specific_library_name='Griptape Nodes Library', node_name='Qwen Image Generation', metadata={'library_node_metadata': {'category': 'image', 'description': 'Generate images using Qwen models via Griptape model proxy'}, 'library': 'Griptape Nodes Library', 'node_type': 'QwenImageGeneration', 'position': {'x': 2216.14914549015, 'y': 296.93529465485886}, 'size': {'width': 719, 'height': 1168}, 'showaddparameter': False, 'category': 'image'}, initial_setup=True)).node_name
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node2_name, source_parameter_name='ruleset', target_node_name=node1_name, target_parameter_name='rulesets_ParameterListUniqueParamID_6df8ae9c0e1a4a1881fc4f3986fbab35', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node0_name, source_parameter_name='text', target_node_name=node3_name, target_parameter_name='input_2', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node0_name, source_parameter_name='text_1', target_node_name=node3_name, target_parameter_name='input_4', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node3_name, source_parameter_name='output', target_node_name=node1_name, target_parameter_name='additional_context', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node1_name, source_parameter_name='output', target_node_name=node11_name, target_parameter_name='prompt', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node11_name, source_parameter_name='image_url', target_node_name=node4_name, target_parameter_name='image_url', initial_setup=True))
    with GriptapeNodes.ContextManager().node(node0_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text', node_name=node0_name, value=top_level_unique_values_dict['1182052f-86f6-4481-a226-b48d679585ad'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text_1', node_name=node0_name, value=top_level_unique_values_dict['11e2fdf7-4cf1-4512-b8ec-e7ef9ab5d641'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node1_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='agent', node_name=node1_name, value=top_level_unique_values_dict['2bb96655-39e1-40b5-805b-62540ca544ea'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='model', node_name=node1_name, value=top_level_unique_values_dict['42107c41-547c-4268-a93e-e69bed45b74d'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='prompt', node_name=node1_name, value=top_level_unique_values_dict['d2df5eb3-bf4f-493d-b988-937bf54832f6'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='additional_context', node_name=node1_name, value=top_level_unique_values_dict['ca72951e-71df-4c87-96a2-fb8aa12529db'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='tools', node_name=node1_name, value=top_level_unique_values_dict['376e3e18-6eaa-4328-bf4b-1a35dfe4c966'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='rulesets', node_name=node1_name, value=top_level_unique_values_dict['996f725e-95a8-4964-b6da-959fcbf05584'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='rulesets_ParameterListUniqueParamID_6df8ae9c0e1a4a1881fc4f3986fbab35', node_name=node1_name, value=top_level_unique_values_dict['2ea5037d-1b26-4d06-ba6f-a3b602f5cfe4'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output', node_name=node1_name, value=top_level_unique_values_dict['6b22c22d-0597-43d6-9533-d4916b22e5d6'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output', node_name=node1_name, value=top_level_unique_values_dict['a01ddd3e-ced9-4d56-8d6d-c41c881e47d2'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='include_details', node_name=node1_name, value=top_level_unique_values_dict['e84f5751-0f21-4276-9c40-9b043a1e3c74'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='logs', node_name=node1_name, value=top_level_unique_values_dict['b84f346a-f57f-4eb4-8457-71f3efa23eca'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node2_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='name', node_name=node2_name, value=top_level_unique_values_dict['09b7071b-fcab-400c-968d-69b9663e8c32'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='rules', node_name=node2_name, value=top_level_unique_values_dict['e7f7f653-9acf-4141-9c1b-89f8c2d4e55b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='ruleset', node_name=node2_name, value=top_level_unique_values_dict['2ea5037d-1b26-4d06-ba6f-a3b602f5cfe4'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node3_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='input_1', node_name=node3_name, value=top_level_unique_values_dict['e8c05586-a913-472e-8658-eb312bd90ab4'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='input_2', node_name=node3_name, value=top_level_unique_values_dict['1182052f-86f6-4481-a226-b48d679585ad'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='input_3', node_name=node3_name, value=top_level_unique_values_dict['abf0c0a0-d879-4df7-ae43-7d110bc6abc6'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='input_4', node_name=node3_name, value=top_level_unique_values_dict['11e2fdf7-4cf1-4512-b8ec-e7ef9ab5d641'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='merge_string', node_name=node3_name, value=top_level_unique_values_dict['ebd6d0ac-f804-4c57-b860-ee8c13c47f95'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='whitespace', node_name=node3_name, value=top_level_unique_values_dict['e84f5751-0f21-4276-9c40-9b043a1e3c74'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output', node_name=node3_name, value=top_level_unique_values_dict['ca72951e-71df-4c87-96a2-fb8aa12529db'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output', node_name=node3_name, value=top_level_unique_values_dict['ca72951e-71df-4c87-96a2-fb8aa12529db'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node4_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='was_successful', node_name=node4_name, value=top_level_unique_values_dict['81ea17a7-2292-4d6b-abbd-2fe2d78746b9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='was_successful', node_name=node4_name, value=top_level_unique_values_dict['81ea17a7-2292-4d6b-abbd-2fe2d78746b9'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='result_details', node_name=node4_name, value=top_level_unique_values_dict['3f73ef8c-0593-4d6e-acb3-2976bafa2d1b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='result_details', node_name=node4_name, value=top_level_unique_values_dict['3f73ef8c-0593-4d6e-acb3-2976bafa2d1b'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='image_url', node_name=node4_name, value=top_level_unique_values_dict['38e19e07-2a34-442c-857f-161492bbb3d9'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node5_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node5_name, value=top_level_unique_values_dict['efb54591-47a3-4245-8f6e-1fe273bacf25'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node6_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node6_name, value=top_level_unique_values_dict['3f8fa8de-2bbb-4a07-8277-2a4a390d90bd'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node7_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node7_name, value=top_level_unique_values_dict['1670e178-4d51-42e3-b7cb-d39e68d4746a'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node8_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node8_name, value=top_level_unique_values_dict['bbd5afde-e94b-4bf9-a398-ca5095fb5752'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node9_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node9_name, value=top_level_unique_values_dict['c6b912d9-1c40-4af6-8b14-8868710d114e'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node10_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node10_name, value=top_level_unique_values_dict['826ef3b9-af7f-46b2-8aeb-bf8742d59203'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node11_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='model', node_name=node11_name, value=top_level_unique_values_dict['bef04d2b-be18-451e-8de3-a7a460d8654e'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='prompt', node_name=node11_name, value=top_level_unique_values_dict['a01ddd3e-ced9-4d56-8d6d-c41c881e47d2'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='size', node_name=node11_name, value=top_level_unique_values_dict['065f2b01-0d2b-4d6f-bd10-9443a7bd768b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='prompt_extend', node_name=node11_name, value=top_level_unique_values_dict['e84f5751-0f21-4276-9c40-9b043a1e3c74'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='watermark', node_name=node11_name, value=top_level_unique_values_dict['e84f5751-0f21-4276-9c40-9b043a1e3c74'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='randomize_seed', node_name=node11_name, value=top_level_unique_values_dict['e84f5751-0f21-4276-9c40-9b043a1e3c74'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='seed', node_name=node11_name, value=top_level_unique_values_dict['32a1389a-3951-4515-8111-c179bff467f1'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='was_successful', node_name=node11_name, value=top_level_unique_values_dict['e84f5751-0f21-4276-9c40-9b043a1e3c74'], initial_setup=True, is_output=False))

def _ensure_workflow_context():
    context_manager = GriptapeNodes.ContextManager()
    if not context_manager.has_current_flow():
        top_level_flow_request = GetTopLevelFlowRequest()
        top_level_flow_result = GriptapeNodes.handle_request(top_level_flow_request)
        if isinstance(top_level_flow_result, GetTopLevelFlowResultSuccess) and top_level_flow_result.flow_name is not None:
            flow_manager = GriptapeNodes.FlowManager()
            flow_obj = flow_manager.get_flow_by_name(top_level_flow_result.flow_name)
            context_manager.push_flow(flow_obj)

def execute_workflow(input: dict, storage_backend: str='local', workflow_executor: WorkflowExecutor | None=None, pickle_control_flow_result: bool=False) -> dict | None:
    return asyncio.run(aexecute_workflow(input=input, storage_backend=storage_backend, workflow_executor=workflow_executor, pickle_control_flow_result=pickle_control_flow_result))

async def aexecute_workflow(input: dict, storage_backend: str='local', workflow_executor: WorkflowExecutor | None=None, pickle_control_flow_result: bool=False) -> dict | None:
    _ensure_workflow_context()
    storage_backend_enum = StorageBackend(storage_backend)
    workflow_executor = workflow_executor or LocalWorkflowExecutor(storage_backend=storage_backend_enum)
    async with workflow_executor as executor:
        await executor.arun(flow_input=input, pickle_control_flow_result=pickle_control_flow_result)
    return executor.output

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--storage-backend', choices=['local', 'gtc'], default='local', help="Storage backend to use: 'local' for local filesystem or 'gtc' for Griptape Cloud")
    parser.add_argument('--json-input', default=None, help='JSON string containing parameter values. Takes precedence over individual parameter arguments if provided.')
    parser.add_argument('--exec_out', default=None, help='Connection to the next node in the execution chain')
    parser.add_argument('--text', default=None, help='New parameter')
    parser.add_argument('--text_1', default=None, help='New parameter')
    args = parser.parse_args()
    flow_input = {}
    if args.json_input is not None:
        flow_input = json.loads(args.json_input)
    if args.json_input is None:
        if 'Start Flow' not in flow_input:
            flow_input['Start Flow'] = {}
        if args.exec_out is not None:
            flow_input['Start Flow']['exec_out'] = args.exec_out
        if args.text is not None:
            flow_input['Start Flow']['text'] = args.text
        if args.text_1 is not None:
            flow_input['Start Flow']['text_1'] = args.text_1
    workflow_output = execute_workflow(input=flow_input, storage_backend=args.storage_backend)
    print(workflow_output)
