# /// script
# dependencies = []
# 
# [tool.griptape-nodes]
# name = "Flux_2_-_Magazine_Cover"
# schema_version = "0.14.0"
# engine_version_created_with = "0.71.0"
# node_libraries_referenced = [["Griptape Nodes Library", "0.59.0"]]
# node_types_used = [["Griptape Nodes Library", "Agent"], ["Griptape Nodes Library", "EndFlow"], ["Griptape Nodes Library", "Flux2ImageGeneration"], ["Griptape Nodes Library", "MergeTexts"], ["Griptape Nodes Library", "Note"], ["Griptape Nodes Library", "Ruleset"], ["Griptape Nodes Library", "StartFlow"]]
# description = "Generate an image for a topical magazine cover using Black Forest Labs Flux.2 Text to Image generation, along with OpenAI gpt-4.1-mini to guide the prompt."
# is_griptape_provided = true
# is_template = true
# creation_date = 2026-01-27T22:25:47.605991Z
# last_modified_date = 2026-01-27T22:25:47.632283Z
# workflow_shape = "{\"inputs\":{\"Start Flow\":{\"exec_out\":{\"name\":\"exec_out\",\"tooltip\":\"Connection to the next node in the execution chain\",\"type\":\"parametercontroltype\",\"input_types\":[\"parametercontroltype\"],\"output_type\":\"parametercontroltype\",\"default_value\":null,\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"display_name\":\"Flow Out\"},\"settable\":true,\"is_user_defined\":true,\"private\":false,\"parent_container_name\":null,\"parent_element_name\":null},\"text\":{\"name\":\"text\",\"tooltip\":\"New parameter\",\"type\":\"str\",\"input_types\":[\"any\"],\"output_type\":\"str\",\"default_value\":\"\",\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"multiline\":true,\"placeholder_text\":\"The text content to display\",\"hide_label\":false,\"hide_property\":false,\"is_custom\":true,\"is_user_added\":true,\"hide\":false,\"display_name\":\"subject\"},\"settable\":true,\"is_user_defined\":true,\"private\":false,\"parent_container_name\":\"\",\"parent_element_name\":null},\"text_1\":{\"name\":\"text_1\",\"tooltip\":\"New parameter\",\"type\":\"str\",\"input_types\":[\"any\"],\"output_type\":\"str\",\"default_value\":\"\",\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"multiline\":true,\"placeholder_text\":\"The text content to display\",\"hide_label\":false,\"hide_property\":false,\"is_custom\":true,\"is_user_added\":true,\"hide\":false,\"display_name\":\"decade\"},\"settable\":true,\"is_user_defined\":true,\"private\":false,\"parent_container_name\":\"\",\"parent_element_name\":null}}},\"outputs\":{\"End Flow\":{\"exec_in\":{\"name\":\"exec_in\",\"tooltip\":\"Control path when the flow completed successfully\",\"type\":\"parametercontroltype\",\"input_types\":[\"parametercontroltype\"],\"output_type\":\"parametercontroltype\",\"default_value\":null,\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"display_name\":\"Succeeded\"},\"settable\":true,\"is_user_defined\":true,\"private\":false,\"parent_container_name\":null,\"parent_element_name\":null},\"failed\":{\"name\":\"failed\",\"tooltip\":\"Control path when the flow failed\",\"type\":\"parametercontroltype\",\"input_types\":[\"parametercontroltype\"],\"output_type\":\"parametercontroltype\",\"default_value\":null,\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"display_name\":\"Failed\"},\"settable\":true,\"is_user_defined\":true,\"private\":false,\"parent_container_name\":null,\"parent_element_name\":null},\"was_successful\":{\"name\":\"was_successful\",\"tooltip\":\"Indicates whether it completed without errors.\",\"type\":\"bool\",\"input_types\":[\"bool\"],\"output_type\":\"bool\",\"default_value\":false,\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{},\"settable\":false,\"is_user_defined\":true,\"private\":false,\"parent_container_name\":null,\"parent_element_name\":null},\"result_details\":{\"name\":\"result_details\",\"tooltip\":\"Details about the operation result\",\"type\":\"str\",\"input_types\":[\"str\"],\"output_type\":\"str\",\"default_value\":null,\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"multiline\":true,\"placeholder_text\":\"Details about the completion or failure will be shown here.\"},\"settable\":false,\"is_user_defined\":true,\"private\":false,\"parent_container_name\":null,\"parent_element_name\":null},\"image_url\":{\"name\":\"image_url\",\"tooltip\":\"New parameter\",\"type\":\"ImageUrlArtifact\",\"input_types\":[\"any\"],\"output_type\":\"ImageUrlArtifact\",\"default_value\":\"\",\"tooltip_as_input\":null,\"tooltip_as_property\":null,\"tooltip_as_output\":null,\"ui_options\":{\"pulse_on_run\":true,\"clickable_file_browser\":true,\"hide_label\":false,\"hide_property\":false,\"is_custom\":true,\"is_user_added\":true},\"settable\":true,\"is_user_defined\":true,\"private\":false,\"parent_container_name\":\"\",\"parent_element_name\":null}}}}"
# image = "https://raw.githubusercontent.com/griptape-ai/griptape-nodes/refs/heads/main/libraries/griptape_nodes_library/workflows/templates/thumbnail_flux_2_-_magazine_cover.webp"
#
# ///

import argparse
import asyncio
import json
import pickle
from griptape.rules.ruleset import Ruleset
from griptape_nodes.bootstrap.workflow_executors.local_workflow_executor import LocalWorkflowExecutor
from griptape_nodes.bootstrap.workflow_executors.workflow_executor import WorkflowExecutor
from griptape_nodes.drivers.storage.storage_backend import StorageBackend
from griptape_nodes.node_library.library_registry import IconVariant, NodeDeprecationMetadata, NodeMetadata
from griptape_nodes.retained_mode.events.connection_events import CreateConnectionRequest
from griptape_nodes.retained_mode.events.flow_events import CreateFlowRequest, GetTopLevelFlowRequest, GetTopLevelFlowResultSuccess
from griptape_nodes.retained_mode.events.library_events import LoadLibrariesRequest
from griptape_nodes.retained_mode.events.node_events import CreateNodeRequest
from griptape_nodes.retained_mode.events.parameter_events import AddParameterToNodeRequest, AlterParameterDetailsRequest, SetParameterValueRequest
from griptape_nodes.retained_mode.griptape_nodes import GriptapeNodes

GriptapeNodes.handle_request(LoadLibrariesRequest())

context_manager = GriptapeNodes.ContextManager()

if not context_manager.has_current_workflow():
    context_manager.push_workflow(workflow_name='Flux_2_-_Magazine_Cover')

"""
1. We've collated all of the unique parameter values into a dictionary so that we do not have to duplicate them.
   This minimizes the size of the code, especially for large objects like serialized image files.
2. We're using a prefix so that it's clear which Flow these values are associated with.
3. The values are serialized using pickle, which is a binary format. This makes them harder to read, but makes
   them consistently save and load. It allows us to serialize complex objects like custom classes, which otherwise
   would be difficult to serialize.
"""
top_level_unique_values_dict = {'636c4abb-3d7c-492e-9539-13a419ea318c': pickle.loads(b'\x80\x04\x95)\x00\x00\x00\x00\x00\x00\x00\x8c%a plastic skateboarding action figure\x94.'), 'f69c757b-87ef-4437-8077-d6847d4c0fdc': pickle.loads(b'\x80\x04\x95\x10\x00\x00\x00\x00\x00\x00\x00\x8c\x0c1990s grunge\x94.'), '29d489d0-e79f-4032-9c5e-3342e3e82127': pickle.loads(b'\x80\x04\x95\x1a\x00\x00\x00\x00\x00\x00\x00\x8c\x16Flux 2 Prompting Guide\x94.'), '07b413cf-f35b-4607-b745-59f6d3fb0479': pickle.loads(b'\x80\x04\x95\x18\r\x00\x00\x00\x00\x00\x00X\x11\r\x00\x00**Rules for Crafting Prompts:**\n\n1. **Focus on Positive Descriptions**  \n   - Avoid negative prompts. Describe what you want clearly.  \n   - Example: Use "sharp focus throughout" instead of "no blur."\n\n2. **Prompt Structure**  \n   - Follow: **Subject + Action + Style + Context**  \n   - Example:  \n     - *"Black cat hiding behind a watermelon slice, professional studio shot, bright red and turquoise background with summer mystery vibe."*\n\n3. **Prioritize Word Order**  \n   - Place the most important details first: **Main subject \xe2\x86\x92 Key action \xe2\x86\x92 Style \xe2\x86\x92 Context \xe2\x86\x92 Secondary details.**\n\n4. **Prompt Length**  \n   - **Short (10\xe2\x80\x9330 words)**: Quick concepts.  \n   - **Medium (30\xe2\x80\x9380 words)**: Ideal for most prompts.  \n   - **Long (80+ words)**: For detailed scenes.\n\n5. **Photorealistic Styles**  \n   - Reference eras, cameras, or techniques for specific looks.  \n   - Example: *"Shot on Kodak Portra 400, natural grain, organic colors."*\n\n6. **Camera and Lens Details**  \n   - Specify models, lenses, and settings for realism.  \n   - Example: *"Canon 5D Mark IV, 24-70mm at 35mm, golden hour, shallow depth of field."*\n\n7. **Typography and Design**  \n   - Use quotation marks for text elements and specify placement, style, and color.  \n   - Example: *"The text \'OPEN\' appears in red neon letters above the door."*\n\n8. **Precise Colors with HEX Codes**  \n   - Use hex codes for exact color matching.  \n   - Example: *"The vase is #02eb3c, with a background of #1a1a2e."*\n\n9. **Multi-Language Support**  \n   - Prompt in your native language for cultural authenticity.  \n   - Example: *"Un march\xc3\xa9 alimentaire dans la campagne normande, lever de soleil, temps un peu brumeux."*\n\n10. **Comic Strips and Sequential Art**  \n    - Maintain consistent character descriptions across panels.  \n    - Example:  \n      - Panel 1: *"Worried scientist typing on glowing holographic keyboard."*  \n      - Panel 2: *"Diffusion Man glows with swirling gradients of purple and blue energy."*\n\n11. **JSON for Complex Scenes**  \n    - Use structured JSON for precise control.  \n    - Example:  \n      ```json\n      {\n        "scene": "Professional studio product photography setup",\n        "subjects": [\n          {\n            "description": "Minimalist ceramic coffee mug with steam rising",\n            "position": "Center foreground",\n            "color_palette": ["matte black ceramic"]\n          }\n        ],\n        "style": "Ultra-realistic product photography",\n        "lighting": "Softbox setup creating diffused highlights",\n        "camera": {\n          "angle": "high angle",\n          "lens-mm": 85,\n          "f-number": "f/5.6"\n        }\n      }\n      ```\n\n12. **Aspect Ratios and Resolution**  \n    - Choose aspect ratios based on use case:  \n      - **1:1**: Social media.  \n      - **16:9**: Cinematic shots.  \n      - **9:16**: Mobile content.  \n      - **4:3**: Magazine layouts.  \n      - **21:9**: Panoramas.  \n    - Recommended resolution: Up to 2MP.\n\n13. **Best Practices Summary**  \n    - **Describe What You Want**: Focus on desired elements.  \n    - **Be Specific with Colors**: Use hex codes for precision.  \n    - **Reference Camera and Style**: Specify models and techniques.  \n    - **Use Native Languages**: Prompt in culturally relevant languages.  \n    - **Structure for Control**: Use JSON for detailed automation.\n\x94.'), 'c1db521f-357a-4487-940e-7ac2bb721fdc': pickle.loads(b'\x80\x04\x95G\x10\x00\x00\x00\x00\x00\x00\x8c\x16griptape.rules.ruleset\x94\x8c\x07Ruleset\x94\x93\x94)\x81\x94}\x94(\x8c\x04type\x94\x8c\x07Ruleset\x94\x8c\x0bmodule_name\x94\x8c\x16griptape.rules.ruleset\x94\x8c\x02id\x94\x8c aa0c1a894a1e45a582f4d821f9f45595\x94\x8c\x04name\x94\x8c\x16Flux 2 Prompting Guide\x94\x8c\x0eruleset_driver\x94\x8c-griptape.drivers.ruleset.local_ruleset_driver\x94\x8c\x12LocalRulesetDriver\x94\x93\x94)\x81\x94}\x94(h\x05\x8c\x12LocalRulesetDriver\x94h\x07\x8c-griptape.drivers.ruleset.local_ruleset_driver\x94\x8c\x0fraise_not_found\x94\x88\x8c\x0bpersist_dir\x94Nub\x8c\x04meta\x94}\x94\x8c\x05rules\x94]\x94(\x8c\x13griptape.rules.rule\x94\x8c\x04Rule\x94\x93\x94)\x81\x94}\x94(h\x05\x8c\x04Rule\x94h\x07\x8c\x13griptape.rules.rule\x94h\x17}\x94\x8c\x05value\x94\x8c\x1f**Rules for Crafting Prompts:**\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xa71. **Focus on Positive Descriptions**  \n   - Avoid negative prompts. Describe what you want clearly.  \n   - Example: Use "sharp focus throughout" instead of "no blur."\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xee2. **Prompt Structure**  \n   - Follow: **Subject + Action + Style + Context**  \n   - Example:  \n     - *"Black cat hiding behind a watermelon slice, professional studio shot, bright red and turquoise background with summer mystery vibe."*\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\x983. **Prioritize Word Order**  \n   - Place the most important details first: **Main subject \xe2\x86\x92 Key action \xe2\x86\x92 Style \xe2\x86\x92 Context \xe2\x86\x92 Secondary details.**\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xb34. **Prompt Length**  \n   - **Short (10\xe2\x80\x9330 words)**: Quick concepts.  \n   - **Medium (30\xe2\x80\x9380 words)**: Ideal for most prompts.  \n   - **Long (80+ words)**: For detailed scenes.\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xab5. **Photorealistic Styles**  \n   - Reference eras, cameras, or techniques for specific looks.  \n   - Example: *"Shot on Kodak Portra 400, natural grain, organic colors."*\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xb36. **Camera and Lens Details**  \n   - Specify models, lenses, and settings for realism.  \n   - Example: *"Canon 5D Mark IV, 24-70mm at 35mm, golden hour, shallow depth of field."*\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xc27. **Typography and Design**  \n   - Use quotation marks for text elements and specify placement, style, and color.  \n   - Example: *"The text \'OPEN\' appears in red neon letters above the door."*\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\x9a8. **Precise Colors with HEX Codes**  \n   - Use hex codes for exact color matching.  \n   - Example: *"The vase is #02eb3c, with a background of #1a1a2e."*\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#\x8c\xcb9. **Multi-Language Support**  \n   - Prompt in your native language for cultural authenticity.  \n   - Example: *"Un march\xc3\xa9 alimentaire dans la campagne normande, lever de soleil, temps un peu brumeux."*\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#X)\x01\x00\x0010. **Comic Strips and Sequential Art**  \n    - Maintain consistent character descriptions across panels.  \n    - Example:  \n      - Panel 1: *"Worried scientist typing on glowing holographic keyboard."*  \n      - Panel 2: *"Diffusion Man glows with swirling gradients of purple and blue energy."*\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#X\xa6\x02\x00\x0011. **JSON for Complex Scenes**  \n    - Use structured JSON for precise control.  \n    - Example:  \n      ```json\n      {\n        "scene": "Professional studio product photography setup",\n        "subjects": [\n          {\n            "description": "Minimalist ceramic coffee mug with steam rising",\n            "position": "Center foreground",\n            "color_palette": ["matte black ceramic"]\n          }\n        ],\n        "style": "Ultra-realistic product photography",\n        "lighting": "Softbox setup creating diffused highlights",\n        "camera": {\n          "angle": "high angle",\n          "lens-mm": 85,\n          "f-number": "f/5.6"\n        }\n      }\n      ```\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#X-\x01\x00\x0012. **Aspect Ratios and Resolution**  \n    - Choose aspect ratios based on use case:  \n      - **1:1**: Social media.  \n      - **16:9**: Cinematic shots.  \n      - **9:16**: Mobile content.  \n      - **4:3**: Magazine layouts.  \n      - **21:9**: Panoramas.  \n    - Recommended resolution: Up to 2MP.\x94ubh\x1d)\x81\x94}\x94(h\x05h h\x07h!h\x17}\x94h#Xw\x01\x00\x0013. **Best Practices Summary**  \n    - **Describe What You Want**: Focus on desired elements.  \n    - **Be Specific with Colors**: Use hex codes for precision.  \n    - **Reference Camera and Style**: Specify models and techniques.  \n    - **Use Native Languages**: Prompt in culturally relevant languages.  \n    - **Structure for Control**: Use JSON for detailed automation.\n\x94ubeub.'), '3236d161-5b22-4954-b150-853063ec9f99': pickle.loads(b'\x80\x04\x95\x0c\x00\x00\x00\x00\x00\x00\x00\x8c\x08Subject:\x94.'), '95568692-603b-4889-b80c-61e774e86bc4': pickle.loads(b'\x80\x04\x95\x0b\x00\x00\x00\x00\x00\x00\x00\x8c\x07Decade:\x94.'), 'b70c78b1-1d95-43f2-a211-19f7b0fe852a': pickle.loads(b'\x80\x04\x95\x06\x00\x00\x00\x00\x00\x00\x00\x8c\x02\\n\x94.'), '3c5f1e66-c8d8-4d0a-b9dd-2d0c318cfb3b': pickle.loads(b'\x80\x04\x89.'), 'eaa20541-642a-4183-973f-182eda2bd7c7': pickle.loads(b'\x80\x04\x95G\x00\x00\x00\x00\x00\x00\x00\x8cCSubject:\na plastic skateboarding action figure\nDecade:\n1990s grunge\x94.'), 'c465a003-22b5-4a79-af46-b5f19ab70ffe': pickle.loads(b'\x80\x04\x95\x11\x01\x00\x00\x00\x00\x00\x00X\n\x01\x00\x00# Flux 2 - Magazine Cover\n\nThis workflow demonstrates the use of Black Forest Labs Flux 2 Text to Image workflow.\n\nIt uses an Agent with OpenAI gpt-4.1-mini to help develop a powerful prompt to give the Image Generation model.\n\nThen we generate an image using Flux 2\x94.'), 'c3f68973-407d-4a94-8eb6-4e64efc3de9c': pickle.loads(b'\x80\x04\x95P\x00\x00\x00\x00\x00\x00\x00\x8cL# Inputs\n\nProvide a *subject* and a *decade* to create a magazine cover for.\x94.'), '6390434d-ea2d-4fb1-966a-bbeaa0456016': pickle.loads(b'\x80\x04\x95D\x00\x00\x00\x00\x00\x00\x00\x8c@This node merges text into a single message to send to an agent.\x94.'), 'd804695a-f53c-4390-8b6c-f12dd4ff4197': pickle.loads(b'\x80\x04\x95\xbb\x00\x00\x00\x00\x00\x00\x00\x8c\xb7# Agent Behavior\n\nThese rules are adapted from the [Flux.2 Prompting Guide](https://docs.bfl.ai/guides/prompting_guide_flux2) and are given to the agent to help guide their responses.\x94.'), 'c63d5118-ff60-4c42-9031-6183df8a77aa': pickle.loads(b'\x80\x04\x95\x95\x00\x00\x00\x00\x00\x00\x00\x8c\x91Using Agents to create image generation prompts helps ensure consistency in the prompt, and allows you to be a bit more free with how you prompt.\x94.'), '1b865806-b7b0-4c0c-9b23-98feff46298c': pickle.loads(b'\x80\x04\x95\x10\x00\x00\x00\x00\x00\x00\x00\x8c\x0cgpt-4.1-mini\x94.'), '9cfe3e7c-dfd7-471a-84e1-a8090263c6f1': pickle.loads(b'\x80\x04}\x94.'), '83cd844a-c994-433d-8630-bc03f7ef23b7': pickle.loads(b'\x80\x04\x95\x08\x01\x00\x00\x00\x00\x00\x00X\x01\x01\x00\x00Create a magazine cover from specified decade of the following subject. Include an interesting title and some article titles and text. \n\nMake the image and article titles authentic to the time period. \n\nOutput only the Image Generation Prompt in JSON format\x94.'), '0a054459-11d2-4d6d-b463-c31e624c25fd': pickle.loads(b'\x80\x04]\x94.'), '5217f81c-0dfd-4c2e-8bfe-65d7b9257e57': pickle.loads(b'\x80\x04\x95J\x10\x00\x00\x00\x00\x00\x00]\x94\x8c\x16griptape.rules.ruleset\x94\x8c\x07Ruleset\x94\x93\x94)\x81\x94}\x94(\x8c\x04type\x94\x8c\x07Ruleset\x94\x8c\x0bmodule_name\x94\x8c\x16griptape.rules.ruleset\x94\x8c\x02id\x94\x8c aa0c1a894a1e45a582f4d821f9f45595\x94\x8c\x04name\x94\x8c\x16Flux 2 Prompting Guide\x94\x8c\x0eruleset_driver\x94\x8c-griptape.drivers.ruleset.local_ruleset_driver\x94\x8c\x12LocalRulesetDriver\x94\x93\x94)\x81\x94}\x94(h\x06\x8c\x12LocalRulesetDriver\x94h\x08\x8c-griptape.drivers.ruleset.local_ruleset_driver\x94\x8c\x0fraise_not_found\x94\x88\x8c\x0bpersist_dir\x94Nub\x8c\x04meta\x94}\x94\x8c\x05rules\x94]\x94(\x8c\x13griptape.rules.rule\x94\x8c\x04Rule\x94\x93\x94)\x81\x94}\x94(h\x06\x8c\x04Rule\x94h\x08\x8c\x13griptape.rules.rule\x94h\x18}\x94\x8c\x05value\x94\x8c\x1f**Rules for Crafting Prompts:**\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xa71. **Focus on Positive Descriptions**  \n   - Avoid negative prompts. Describe what you want clearly.  \n   - Example: Use "sharp focus throughout" instead of "no blur."\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xee2. **Prompt Structure**  \n   - Follow: **Subject + Action + Style + Context**  \n   - Example:  \n     - *"Black cat hiding behind a watermelon slice, professional studio shot, bright red and turquoise background with summer mystery vibe."*\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\x983. **Prioritize Word Order**  \n   - Place the most important details first: **Main subject \xe2\x86\x92 Key action \xe2\x86\x92 Style \xe2\x86\x92 Context \xe2\x86\x92 Secondary details.**\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xb34. **Prompt Length**  \n   - **Short (10\xe2\x80\x9330 words)**: Quick concepts.  \n   - **Medium (30\xe2\x80\x9380 words)**: Ideal for most prompts.  \n   - **Long (80+ words)**: For detailed scenes.\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xab5. **Photorealistic Styles**  \n   - Reference eras, cameras, or techniques for specific looks.  \n   - Example: *"Shot on Kodak Portra 400, natural grain, organic colors."*\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xb36. **Camera and Lens Details**  \n   - Specify models, lenses, and settings for realism.  \n   - Example: *"Canon 5D Mark IV, 24-70mm at 35mm, golden hour, shallow depth of field."*\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xc27. **Typography and Design**  \n   - Use quotation marks for text elements and specify placement, style, and color.  \n   - Example: *"The text \'OPEN\' appears in red neon letters above the door."*\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\x9a8. **Precise Colors with HEX Codes**  \n   - Use hex codes for exact color matching.  \n   - Example: *"The vase is #02eb3c, with a background of #1a1a2e."*\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$\x8c\xcb9. **Multi-Language Support**  \n   - Prompt in your native language for cultural authenticity.  \n   - Example: *"Un march\xc3\xa9 alimentaire dans la campagne normande, lever de soleil, temps un peu brumeux."*\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$X)\x01\x00\x0010. **Comic Strips and Sequential Art**  \n    - Maintain consistent character descriptions across panels.  \n    - Example:  \n      - Panel 1: *"Worried scientist typing on glowing holographic keyboard."*  \n      - Panel 2: *"Diffusion Man glows with swirling gradients of purple and blue energy."*\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$X\xa6\x02\x00\x0011. **JSON for Complex Scenes**  \n    - Use structured JSON for precise control.  \n    - Example:  \n      ```json\n      {\n        "scene": "Professional studio product photography setup",\n        "subjects": [\n          {\n            "description": "Minimalist ceramic coffee mug with steam rising",\n            "position": "Center foreground",\n            "color_palette": ["matte black ceramic"]\n          }\n        ],\n        "style": "Ultra-realistic product photography",\n        "lighting": "Softbox setup creating diffused highlights",\n        "camera": {\n          "angle": "high angle",\n          "lens-mm": 85,\n          "f-number": "f/5.6"\n        }\n      }\n      ```\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$X-\x01\x00\x0012. **Aspect Ratios and Resolution**  \n    - Choose aspect ratios based on use case:  \n      - **1:1**: Social media.  \n      - **16:9**: Cinematic shots.  \n      - **9:16**: Mobile content.  \n      - **4:3**: Magazine layouts.  \n      - **21:9**: Panoramas.  \n    - Recommended resolution: Up to 2MP.\x94ubh\x1e)\x81\x94}\x94(h\x06h!h\x08h"h\x18}\x94h$Xw\x01\x00\x0013. **Best Practices Summary**  \n    - **Describe What You Want**: Focus on desired elements.  \n    - **Be Specific with Colors**: Use hex codes for precision.  \n    - **Reference Camera and Style**: Specify models and techniques.  \n    - **Use Native Languages**: Prompt in culturally relevant languages.  \n    - **Structure for Control**: Use JSON for detailed automation.\n\x94ubeuba.'), '32195bc2-8385-4d78-a013-529e7c208509': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00\x8c\x00\x94.'), 'f426f470-f9c4-4e65-8e41-0d4d370f355c': pickle.loads(b'\x80\x04\x95\x10\x00\x00\x00\x00\x00\x00\x00\x8c\x0cFlux.2 [pro]\x94.'), 'ae832f14-6758-4509-8860-a038b0053435': pickle.loads(b'\x80\x04]\x94.'), 'efc0704a-0d22-4d58-b084-6d44b536cda2': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00M\x80\x03.'), '30639830-9f12-43d5-9625-c2287e673be7': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00M\x80\x04.'), '75b896c9-9c70-40b6-8511-4a682a7cdbe3': pickle.loads(b'\x80\x04\x88.'), '39d9f563-5c68-4d3b-9c6e-a98d4054970f': pickle.loads(b'\x80\x04K*.'), 'b8b7490c-1880-429d-9832-f50f7df6d5ee': pickle.loads(b'\x80\x04\x95\x08\x00\x00\x00\x00\x00\x00\x00\x8c\x04jpeg\x94.'), 'bf646090-a4f2-4f53-823f-0016864dc13d': pickle.loads(b'\x80\x04\x95\x15\x00\x00\x00\x00\x00\x00\x00\x8c\x11least restrictive\x94.'), '60501c50-f362-4c2d-914a-c0a9c3671942': pickle.loads(b'\x80\x04K2.'), '9a17b6f8-bc07-4cf8-8d5e-fb7e385207fb': pickle.loads(b'\x80\x04\x95\n\x00\x00\x00\x00\x00\x00\x00G@\x12\x00\x00\x00\x00\x00\x00.'), '01c94547-f7f5-4a32-9af2-c3bfb146dc9f': pickle.loads(b"\x80\x04\x95'\x00\x00\x00\x00\x00\x00\x00\x8c#Generate the image using flux-2-max\x94."), '927d956d-daf6-4259-91ff-cac11fade28c': pickle.loads(b'\x80\x04\x95\x16\x00\x00\x00\x00\x00\x00\x00\x8c\x12Output the results\x94.')}

'# Create the Flow, then do work within it as context.'

flow0_name = GriptapeNodes.handle_request(CreateFlowRequest(parent_flow_name=None, flow_name='ControlFlow_1', set_as_new_context=False, metadata={})).flow_name

with GriptapeNodes.ContextManager().flow(flow0_name):
    node0_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='StartFlow', specific_library_name='Griptape Nodes Library', node_name='Start Flow', metadata={'position': {'x': -1061.5751704894092, 'y': 296.93529465485886}, 'tempId': 'placing-1765996350930-qa8fpl', 'library_node_metadata': NodeMetadata(category='workflows', description='Define the start of a workflow and pass parameters into the flow', display_name='Start Flow', tags=None, icon=None, color=None, group='create', deprecation=None, is_node_group=None), 'library': 'Griptape Nodes Library', 'node_type': 'StartFlow', 'showaddparameter': True, 'size': {'width': 600, 'height': 347}, 'category': 'workflows'}, resolution='resolved', initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node0_name):
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='text', default_value='', tooltip='New parameter', type='str', input_types=['any'], output_type='str', ui_options={'multiline': True, 'placeholder_text': 'The text content to display', 'hide_label': False, 'hide_property': False, 'is_custom': True, 'is_user_added': True, 'hide': False, 'display_name': 'subject'}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, parent_container_name='', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='text_1', default_value='', tooltip='New parameter', type='str', input_types=['any'], output_type='str', ui_options={'multiline': True, 'placeholder_text': 'The text content to display', 'hide_label': False, 'hide_property': False, 'is_custom': True, 'is_user_added': True, 'hide': False, 'display_name': 'decade'}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, parent_container_name='', initial_setup=True))
    node1_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Ruleset', specific_library_name='Griptape Nodes Library', node_name='Ruleset_1', metadata={'position': {'x': -140.8654069738245, 'y': 1134.5360838384356}, 'tempId': 'placing-1765998085117-ktqra', 'library_node_metadata': NodeMetadata(category='agents/rules', description='Give an agent a set of rules and behaviors to follow', display_name='Ruleset', tags=None, icon=None, color=None, group='create', deprecation=None, is_node_group=None), 'library': 'Griptape Nodes Library', 'node_type': 'Ruleset', 'showaddparameter': False, 'size': {'width': 864, 'height': 410}, 'category': 'agents/rules'}, resolution='resolved', initial_setup=True)).node_name
    node2_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='MergeTexts', specific_library_name='Griptape Nodes Library', node_name='Merge Texts', metadata={'position': {'x': -140.8654069738245, 'y': 258.80785141297656}, 'tempId': 'placing-1766002459782-pzdym9', 'library_node_metadata': NodeMetadata(category='text', description='MergeTexts node', display_name='Merge Texts', tags=None, icon='merge', color=None, group='merge', deprecation=None, is_node_group=None), 'library': 'Griptape Nodes Library', 'node_type': 'MergeTexts', 'showaddparameter': False, 'size': {'width': 600, 'height': 500}, 'category': 'text', 'empty_merge_string_migrated': True}, resolution='resolved', initial_setup=True)).node_name
    node3_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Workflow Description', metadata={'position': {'x': -1061.5751704894092, 'y': -336.52399023132017}, 'tempId': 'placing-1766158799711-dw55dh', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None, is_node_group=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 600, 'height': 328}, 'category': 'misc'}, initial_setup=True)).node_name
    node4_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 1', metadata={'position': {'x': -1061.5751704894092, 'y': 66.80785141297656}, 'tempId': 'placing-1766003334530-pnkgh', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None, is_node_group=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 600, 'height': 192}, 'category': 'misc'}, resolution='resolved', initial_setup=True)).node_name
    node5_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 2', metadata={'position': {'x': -140.8654069738245, 'y': 66.80785141297656}, 'tempId': 'placing-1766003370124-fo9hq', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None, is_node_group=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 602, 'height': 132}, 'category': 'misc'}, resolution='resolved', initial_setup=True)).node_name
    node6_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 3', metadata={'position': {'x': -140.8654069738245, 'y': 924.8103879646247}, 'tempId': 'placing-1766003265679-b4mek', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None, is_node_group=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 600, 'height': 192}, 'category': 'misc'}, resolution='resolved', initial_setup=True)).node_name
    node7_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 4', metadata={'position': {'x': 973.7080171132445, 'y': 66.80785141297656}, 'tempId': 'placing-1766003370124-fo9hq', 'library_node_metadata': NodeMetadata(category='misc', description='Create a note node to provide helpful context in your workflow', display_name='Note', tags=None, icon='notepad-text', color=None, group='create', deprecation=None, is_node_group=None), 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 600, 'height': 163}, 'category': 'misc'}, resolution='resolved', initial_setup=True)).node_name
    node8_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Agent', specific_library_name='Griptape Nodes Library', node_name='Agent_1', metadata={'library_node_metadata': NodeMetadata(category='agents', description='Creates an AI agent with conversation memory and the ability to use tools', display_name='Agent', tags=None, icon=None, color=None, group='create', deprecation=None, is_node_group=None), 'library': 'Griptape Nodes Library', 'node_type': 'Agent', 'position': {'x': 973.7080171132445, 'y': 258.80785141297656}, 'size': {'width': 600, 'height': 1179}}, initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node8_name):
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='additional_context', mode_allowed_property=False, initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='rulesets_ParameterListUniqueParamID_cfcb1fdadf364b38b44e1e31d82555ad', default_value=[], tooltip='Rulesets to apply to the agent to control its behavior.', type='Ruleset', input_types=['Ruleset', 'list[Ruleset]'], output_type='Ruleset', ui_options={}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=False, is_user_defined=True, settable=True, parent_container_name='rulesets', initial_setup=True))
    node9_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Flux2ImageGeneration', specific_library_name='Griptape Nodes Library', node_name='FLUX.2 Image Generation', metadata={'library_node_metadata': {'category': 'image', 'description': 'Generate images using FLUX.2 models via Griptape model proxy'}, 'library': 'Griptape Nodes Library', 'node_type': 'Flux2ImageGeneration', 'position': {'x': 1859.9823765949673, 'y': 258.80785141297656}, 'size': {'width': 725, 'height': 1245}, 'showaddparameter': False, 'category': 'image'}, initial_setup=True)).node_name
    node10_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 5', metadata={'position': {'x': 1863.852786603357, 'y': 66.80785141297656}, 'tempId': 'placing-1766003370124-fo9hq', 'library_node_metadata': {'category': 'misc', 'description': 'Create a note node to provide helpful context in your workflow'}, 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 722, 'height': 153}, 'category': 'misc'}, initial_setup=True)).node_name
    node11_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='Note', specific_library_name='Griptape Nodes Library', node_name='Step 8', metadata={'position': {'x': 2755.9261113966577, 'y': 66.80785141297656}, 'tempId': 'placing-1766003370124-fo9hq', 'library_node_metadata': {'category': 'misc', 'description': 'Create a note node to provide helpful context in your workflow'}, 'library': 'Griptape Nodes Library', 'node_type': 'Note', 'showaddparameter': False, 'size': {'width': 722, 'height': 153}, 'category': 'misc'}, initial_setup=True)).node_name
    node12_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='EndFlow', specific_library_name='Griptape Nodes Library', node_name='End Flow', metadata={'library_node_metadata': {'category': 'workflows', 'description': 'Define the end of a workflow and return parameters from the flow'}, 'library': 'Griptape Nodes Library', 'node_type': 'EndFlow', 'showaddparameter': True, 'position': {'x': 2755.9261113966577, 'y': 258.80785141297656}, 'size': {'width': 945, 'height': 1244}, 'category': 'workflows'}, initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node12_name):
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='image_url', default_value='', tooltip='New parameter', type='ImageUrlArtifact', input_types=['any'], output_type='ImageUrlArtifact', ui_options={'pulse_on_run': True, 'clickable_file_browser': True, 'hide_label': False, 'hide_property': False, 'is_custom': True, 'is_user_added': True}, mode_allowed_input=True, mode_allowed_property=True, mode_allowed_output=True, parent_container_name='', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node0_name, source_parameter_name='text', target_node_name=node2_name, target_parameter_name='input_2', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node0_name, source_parameter_name='text_1', target_node_name=node2_name, target_parameter_name='input_4', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node2_name, source_parameter_name='output', target_node_name=node8_name, target_parameter_name='additional_context', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node1_name, source_parameter_name='ruleset', target_node_name=node8_name, target_parameter_name='rulesets_ParameterListUniqueParamID_cfcb1fdadf364b38b44e1e31d82555ad', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node8_name, source_parameter_name='output', target_node_name=node9_name, target_parameter_name='prompt', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node9_name, source_parameter_name='image_url', target_node_name=node12_name, target_parameter_name='image_url', initial_setup=True))
    with GriptapeNodes.ContextManager().node(node0_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text', node_name=node0_name, value=top_level_unique_values_dict['636c4abb-3d7c-492e-9539-13a419ea318c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text_1', node_name=node0_name, value=top_level_unique_values_dict['f69c757b-87ef-4437-8077-d6847d4c0fdc'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node1_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='name', node_name=node1_name, value=top_level_unique_values_dict['29d489d0-e79f-4032-9c5e-3342e3e82127'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='rules', node_name=node1_name, value=top_level_unique_values_dict['07b413cf-f35b-4607-b745-59f6d3fb0479'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='ruleset', node_name=node1_name, value=top_level_unique_values_dict['c1db521f-357a-4487-940e-7ac2bb721fdc'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node2_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='input_1', node_name=node2_name, value=top_level_unique_values_dict['3236d161-5b22-4954-b150-853063ec9f99'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='input_2', node_name=node2_name, value=top_level_unique_values_dict['636c4abb-3d7c-492e-9539-13a419ea318c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='input_3', node_name=node2_name, value=top_level_unique_values_dict['95568692-603b-4889-b80c-61e774e86bc4'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='input_4', node_name=node2_name, value=top_level_unique_values_dict['f69c757b-87ef-4437-8077-d6847d4c0fdc'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='merge_string', node_name=node2_name, value=top_level_unique_values_dict['b70c78b1-1d95-43f2-a211-19f7b0fe852a'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='whitespace', node_name=node2_name, value=top_level_unique_values_dict['3c5f1e66-c8d8-4d0a-b9dd-2d0c318cfb3b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output', node_name=node2_name, value=top_level_unique_values_dict['eaa20541-642a-4183-973f-182eda2bd7c7'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output', node_name=node2_name, value=top_level_unique_values_dict['eaa20541-642a-4183-973f-182eda2bd7c7'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node3_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node3_name, value=top_level_unique_values_dict['c465a003-22b5-4a79-af46-b5f19ab70ffe'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node4_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node4_name, value=top_level_unique_values_dict['c3f68973-407d-4a94-8eb6-4e64efc3de9c'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node5_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node5_name, value=top_level_unique_values_dict['6390434d-ea2d-4fb1-966a-bbeaa0456016'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node6_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node6_name, value=top_level_unique_values_dict['d804695a-f53c-4390-8b6c-f12dd4ff4197'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node7_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node7_name, value=top_level_unique_values_dict['c63d5118-ff60-4c42-9031-6183df8a77aa'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node8_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='model', node_name=node8_name, value=top_level_unique_values_dict['1b865806-b7b0-4c0c-9b23-98feff46298c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='agent_memory', node_name=node8_name, value=top_level_unique_values_dict['9cfe3e7c-dfd7-471a-84e1-a8090263c6f1'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='prompt', node_name=node8_name, value=top_level_unique_values_dict['83cd844a-c994-433d-8630-bc03f7ef23b7'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='additional_context', node_name=node8_name, value=top_level_unique_values_dict['eaa20541-642a-4183-973f-182eda2bd7c7'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='tools', node_name=node8_name, value=top_level_unique_values_dict['0a054459-11d2-4d6d-b463-c31e624c25fd'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='rulesets', node_name=node8_name, value=top_level_unique_values_dict['5217f81c-0dfd-4c2e-8bfe-65d7b9257e57'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='rulesets_ParameterListUniqueParamID_cfcb1fdadf364b38b44e1e31d82555ad', node_name=node8_name, value=top_level_unique_values_dict['c1db521f-357a-4487-940e-7ac2bb721fdc'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output', node_name=node8_name, value=top_level_unique_values_dict['32195bc2-8385-4d78-a013-529e7c208509'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='include_details', node_name=node8_name, value=top_level_unique_values_dict['3c5f1e66-c8d8-4d0a-b9dd-2d0c318cfb3b'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node9_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='model', node_name=node9_name, value=top_level_unique_values_dict['f426f470-f9c4-4e65-8e41-0d4d370f355c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='prompt', node_name=node9_name, value=top_level_unique_values_dict['32195bc2-8385-4d78-a013-529e7c208509'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='input_images', node_name=node9_name, value=top_level_unique_values_dict['ae832f14-6758-4509-8860-a038b0053435'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='width', node_name=node9_name, value=top_level_unique_values_dict['efc0704a-0d22-4d58-b084-6d44b536cda2'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='height', node_name=node9_name, value=top_level_unique_values_dict['30639830-9f12-43d5-9625-c2287e673be7'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='force_output_dimension', node_name=node9_name, value=top_level_unique_values_dict['75b896c9-9c70-40b6-8511-4a682a7cdbe3'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='randomize_seed', node_name=node9_name, value=top_level_unique_values_dict['3c5f1e66-c8d8-4d0a-b9dd-2d0c318cfb3b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='seed', node_name=node9_name, value=top_level_unique_values_dict['39d9f563-5c68-4d3b-9c6e-a98d4054970f'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='output_format', node_name=node9_name, value=top_level_unique_values_dict['b8b7490c-1880-429d-9832-f50f7df6d5ee'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='safety_tolerance', node_name=node9_name, value=top_level_unique_values_dict['bf646090-a4f2-4f53-823f-0016864dc13d'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='steps', node_name=node9_name, value=top_level_unique_values_dict['60501c50-f362-4c2d-914a-c0a9c3671942'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='guidance', node_name=node9_name, value=top_level_unique_values_dict['9a17b6f8-bc07-4cf8-8d5e-fb7e385207fb'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='was_successful', node_name=node9_name, value=top_level_unique_values_dict['3c5f1e66-c8d8-4d0a-b9dd-2d0c318cfb3b'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node10_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node10_name, value=top_level_unique_values_dict['01c94547-f7f5-4a32-9af2-c3bfb146dc9f'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node11_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='note', node_name=node11_name, value=top_level_unique_values_dict['927d956d-daf6-4259-91ff-cac11fade28c'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node12_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='was_successful', node_name=node12_name, value=top_level_unique_values_dict['3c5f1e66-c8d8-4d0a-b9dd-2d0c318cfb3b'], initial_setup=True, is_output=False))

def _ensure_workflow_context():
    context_manager = GriptapeNodes.ContextManager()
    if not context_manager.has_current_flow():
        top_level_flow_request = GetTopLevelFlowRequest()
        top_level_flow_result = GriptapeNodes.handle_request(top_level_flow_request)
        if isinstance(top_level_flow_result, GetTopLevelFlowResultSuccess) and top_level_flow_result.flow_name is not None:
            flow_manager = GriptapeNodes.FlowManager()
            flow_obj = flow_manager.get_flow_by_name(top_level_flow_result.flow_name)
            context_manager.push_flow(flow_obj)

def execute_workflow(input: dict, storage_backend: str='local', workflow_executor: WorkflowExecutor | None=None, pickle_control_flow_result: bool=False) -> dict | None:
    return asyncio.run(aexecute_workflow(input=input, storage_backend=storage_backend, workflow_executor=workflow_executor, pickle_control_flow_result=pickle_control_flow_result))

async def aexecute_workflow(input: dict, storage_backend: str='local', workflow_executor: WorkflowExecutor | None=None, pickle_control_flow_result: bool=False) -> dict | None:
    _ensure_workflow_context()
    storage_backend_enum = StorageBackend(storage_backend)
    workflow_executor = workflow_executor or LocalWorkflowExecutor(storage_backend=storage_backend_enum)
    async with workflow_executor as executor:
        await executor.arun(flow_input=input, pickle_control_flow_result=pickle_control_flow_result)
    return executor.output

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--storage-backend', choices=['local', 'gtc'], default='local', help="Storage backend to use: 'local' for local filesystem or 'gtc' for Griptape Cloud")
    parser.add_argument('--json-input', default=None, help='JSON string containing parameter values. Takes precedence over individual parameter arguments if provided.')
    parser.add_argument('--exec_out', default=None, help='Connection to the next node in the execution chain')
    parser.add_argument('--text', default=None, help='New parameter')
    parser.add_argument('--text_1', default=None, help='New parameter')
    args = parser.parse_args()
    flow_input = {}
    if args.json_input is not None:
        flow_input = json.loads(args.json_input)
    if args.json_input is None:
        if 'Start Flow' not in flow_input:
            flow_input['Start Flow'] = {}
        if args.exec_out is not None:
            flow_input['Start Flow']['exec_out'] = args.exec_out
        if args.text is not None:
            flow_input['Start Flow']['text'] = args.text
        if args.text_1 is not None:
            flow_input['Start Flow']['text_1'] = args.text_1
    workflow_output = execute_workflow(input=flow_input, storage_backend=args.storage_backend)
    print(workflow_output)
